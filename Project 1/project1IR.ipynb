{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in /Users/mahek/opt/anaconda3/lib/python3.8/site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in /Users/mahek/opt/anaconda3/lib/python3.8/site-packages (from textblob) (3.5)\n",
      "Requirement already satisfied: click in /Users/mahek/opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.1->textblob) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /Users/mahek/opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.1->textblob) (4.47.0)\n",
      "Requirement already satisfied: joblib in /Users/mahek/opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.1->textblob) (0.16.0)\n",
      "Requirement already satisfied: regex in /Users/mahek/opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.1->textblob) (2020.6.8)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy import OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    "import tweepy\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import string\n",
    "import preprocessor as p\n",
    "import os\n",
    "import time\n",
    "import string\n",
    "from tweepy import OAuthHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter credentials\n",
    "# Obtain them from your twitter developer account\n",
    "consumer_key = \"XNDLnNA9i3Xj49EjE86kGZS9B\"\n",
    "consumer_secret = \"Cd0lqCAtAs6EZu24UsfRGpFoShAseD1LF4VpPZgMhEjdporOR7\"\n",
    "access_key = \"721550660290920448-1EJdARFRG1l6LuOfi1dK1lcowVeUIc9\"\n",
    "access_secret = \"50mzkBjDyRGnDb7pqdkGV2M7yJL5DZRqDomePFYa8QYiI\"\n",
    "# Pass your twitter credentials to tweepy via its OAuthHandler\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise these variables:\n",
    "search_words = \"#covid19 AND #government\"\n",
    "date_since = \"2020-09-10\"\n",
    "numTweets = 4\n",
    "numRuns = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraptweets(search_words, date_since, numTweets, numRuns):\n",
    "    \n",
    "    # Define a for-loop to generate tweets at regular intervals\n",
    "    # We cannot make large API call in one go. Hence, let's try T times\n",
    "    \n",
    "    # Define a pandas dataframe to store the date:\n",
    "    db_tweets = pd.DataFrame(columns = ['username', 'acctdesc', 'location', 'following',\n",
    "                                        'followers', 'totaltweets', 'usercreatedts', 'tweetcreatedts',\n",
    "                                        'retweetcount', 'text', 'hashtags']\n",
    "                                )\n",
    "    program_start = time.time()\n",
    "    for i in range(0, numRuns):\n",
    "        # We will time how long it takes to scrape tweets for each run:\n",
    "        start_run = time.time()\n",
    "        \n",
    "        # Collect tweets using the Cursor object\n",
    "        # .Cursor() returns an object that you can iterate or loop over to access the data collected.\n",
    "        # Each item in the iterator has various attributes that you can access to get information about each tweet\n",
    "        tweets = tweepy.Cursor(api.search, q=search_words, lang=\"en\", since=date_since, tweet_mode='extended').items(numTweets)\n",
    "# Store these tweets into a python list\n",
    "        tweet_list = [tweet for tweet in tweets]\n",
    "# Obtain the following info (methods to call them out):\n",
    "        # user.screen_name - twitter handle\n",
    "        # user.description - description of account\n",
    "        # user.location - where is he tweeting from\n",
    "        # user.friends_count - no. of other users that user is following (following)\n",
    "        # user.followers_count - no. of other users who are following this user (followers)\n",
    "        # user.statuses_count - total tweets by user\n",
    "        # user.created_at - when the user account was created\n",
    "        # created_at - when the tweet was created\n",
    "        # retweet_count - no. of retweets\n",
    "        # (deprecated) user.favourites_count - probably total no. of tweets that is favourited by user\n",
    "        # retweeted_status.full_text - full text of the tweet\n",
    "        # tweet.entities['hashtags'] - hashtags in the tweet\n",
    "# Begin scraping the tweets individually:\n",
    "        noTweets = 0\n",
    "        for tweet in tweet_list:\n",
    "    \n",
    "# Pull the values\n",
    "            username = tweet.user.screen_name\n",
    "            acctdesc = tweet.user.description\n",
    "            location = tweet.user.location\n",
    "            following = tweet.user.friends_count\n",
    "            followers = tweet.user.followers_count\n",
    "            totaltweets = tweet.user.statuses_count\n",
    "            usercreatedts = tweet.user.created_at\n",
    "            tweetcreatedts = tweet.created_at\n",
    "            retweetcount = tweet.retweet_count\n",
    "            hashtags = tweet.entities['hashtags']\n",
    "            try:\n",
    "                text = tweet.retweeted_status.full_text\n",
    "            except AttributeError:  # Not a Retweet\n",
    "                text = tweet.full_text\n",
    "# Add the 11 variables to the empty list - ith_tweet:\n",
    "            ith_tweet = [username, acctdesc, location, following, followers, totaltweets,\n",
    "                         usercreatedts, tweetcreatedts, retweetcount, text, hashtags]\n",
    "# Append to dataframe - db_tweets\n",
    "            db_tweets.loc[len(db_tweets)] = ith_tweet\n",
    "# increase counter - noTweets  \n",
    "            noTweets += 1\n",
    "        \n",
    "        # Run ended:\n",
    "        end_run = time.time()\n",
    "        duration_run = round((end_run-start_run)/60, 2)\n",
    "        \n",
    "        print('no. of tweets scraped for run {} is {}'.format(i + 1, noTweets))\n",
    "        print('time take for {} run to complete is {} mins'.format(i+1, duration_run))\n",
    "        \n",
    "        #time.sleep(920) #15 minute sleep time\n",
    "# Once all runs have completed, save them to a single csv file:\n",
    "   # from datetime import datetime\n",
    "    \n",
    "    # Obtain timestamp in a readable format\n",
    "   # to_csv_timestamp = datetime.today().strftime('%Y%m%d_%H%M%S')\n",
    "# Define working path and filename\n",
    "   # path = os.getcwd()\n",
    "   # filename = path + '/data/' + to_csv_timestamp + '_sahkprotests_tweets.csv'\n",
    "# Store dataframe in csv with creation date timestamp\n",
    "    db_tweets.to_json('/Users/mahek/Desktop/PROJ/proj.json')\n",
    "    print (db_tweets)\n",
    "    program_end = time.time()\n",
    "    print('Scraping has completed!')\n",
    "    print('Total time taken to scrap is {} minutes.'.format(round(program_end - program_start)/60, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 1 is 4\n",
      "time take for 1 run to complete is 0.01 mins\n",
      "         username                                           acctdesc location  \\\n",
      "0  QueenAspergers                                                               \n",
      "1     avgeekmrjnp  ðŸŒŽMy World ðŸ‡¨ðŸ‡¦Toronto, OntarioðŸŽ„December 25th 198...            \n",
      "2         SMA_PIT  Providing a forum to plan and design new educa...            \n",
      "3   crypto_akenai  #Cryptocurrency #blockchain is the future! Ano...            \n",
      "\n",
      "  following followers totaltweets       usercreatedts      tweetcreatedts  \\\n",
      "0       130        51        2846 2017-11-11 01:46:12 2020-09-17 00:57:16   \n",
      "1       394        12         430 2020-08-13 00:19:58 2020-09-17 00:34:37   \n",
      "2         8         4           5 2020-05-27 18:59:46 2020-09-17 00:15:35   \n",
      "3       308        44         110 2020-09-09 00:42:12 2020-09-16 23:25:32   \n",
      "\n",
      "  retweetcount                                               text  \\\n",
      "0            0  ...ever-changing rules. Accept that they may n...   \n",
      "1            0  The united states &amp; Canadian border will r...   \n",
      "2            0  #communications chair: Christine McEvoy is a M...   \n",
      "3            1  The rich will board themselves up while the po...   \n",
      "\n",
      "                                            hashtags  \n",
      "0  [{'text': 'Autism', 'indices': [133, 140]}, {'...  \n",
      "1  [{'text': 'covid19', 'indices': [209, 217]}, {...  \n",
      "2  [{'text': 'communications', 'indices': [0, 15]...  \n",
      "3  [{'text': 'lockdown', 'indices': [130, 139]}, ...  \n",
      "Scraping has completed!\n",
      "Total time taken to scrap is 0.0 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Call the function scraptweets\n",
    "scraptweets(search_words, date_since, numTweets, numRuns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
